{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.1 Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99668579  2.01549469]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "# Creating a function to model and create data\n",
    "def func(x, a, b):\n",
    "    return a * x + b\n",
    "# Generating clean data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = func(x, 1, 2)\n",
    "# Adding noise to the data\n",
    "yn = y + 0.9 * np.random.normal(size=len(x))\n",
    "# Executing curve_fit on noisy data\n",
    "popt, pcov = curve_fit(func, x, yn)\n",
    "# popt returns the best fit values for parameters of\n",
    "# the given model (func).\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.05004551  4.97825552 -1.80976275]\n"
     ]
    }
   ],
   "source": [
    "# Creating a function to model and create data\n",
    "def func(x, a, b, c):\n",
    "    return a*np.exp(-(x-b)**2/(2*c**2))\n",
    "\n",
    "# Generating clean data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = func(x, 1, 5, 2)\n",
    "# Adding noise to the data\n",
    "yn = y + 0.2 * np.random.normal(size=len(x))\n",
    "# Executing curve_fit on noisy data\n",
    "popt, pcov = curve_fit(func, x, yn)\n",
    "# popt returns the best-fit values for parameters of the given model (func).\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Two-Gaussian model\n",
    "def func(x, a0, b0, c0, a1, b1,c1):\n",
    "    return a0*np.exp(-(x - b0) ** 2/(2 * c0 ** 2))\\\n",
    "+ a1 * np.exp(-(x - b1) ** 2/(2 * c1 ** 2))\n",
    "\n",
    "# Generating clean data\n",
    "x = np.linspace(0, 20, 200)\n",
    "y = func(x, 1, 3, 1, -2, 15, 0.5)\n",
    "# Adding noise to the data\n",
    "yn = y + 0.2 * np.random.normal(size=len(x))\n",
    "# Since we are fitting a more complex function,\n",
    "# providing guesses for the fitting will lead to\n",
    "# better results.\n",
    "guesses = [1, 3, 1, 1, 15, 1]\n",
    "# Executing curve_fit on noisy data\n",
    "popt, pcov = curve_fit(func, x, yn, p0=guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "import numpy as np\n",
    "line = lambda x: x + 3\n",
    "solution = fsolve(line, -2)\n",
    "print solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 13.40773078,  18.11366128,  31.78330863,  37.0799992 ,\n",
      "        39.84837786,  43.8258775 ]), array([-0.36592269, -0.31886339, -0.18216691, -0.12920001, -0.10151622,\n",
      "       -0.06174122]))\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "import numpy as np\n",
    "# Defining function to simplify intersection solution\n",
    "def findIntersection(func1, func2, x0):\n",
    "    return fsolve(lambda x : func1(x) - func2(x), x0)\n",
    "\n",
    "# Defining functions that will intersect\n",
    "funky = lambda x : np.cos(x / 5) * np.sin(x / 2)\n",
    "line = lambda x : 0.01 * x - 0.5\n",
    "# Defining range and getting solutions on intersection points\n",
    "x = np.linspace(0,45,10000)\n",
    "result = findIntersection(funky, line, [15, 20, 30, 35, 40, 45])\n",
    "# Printing out results for x and y\n",
    "print(result, line(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.2 Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "# Setting up fake data\n",
    "x = np.linspace(0, 10 * np.pi, 20)\n",
    "y = np.cos(x)\n",
    "# Interpolating data\n",
    "fl = interp1d(x, y, kind='linear')\n",
    "fq = interp1d(x, y, kind='quadratic')\n",
    "# x.min and x.max are used to make sure we do not\n",
    "# go beyond the boundaries of the data for the\n",
    "# interpolation.\n",
    "xint = np.linspace(x.min(), x.max(), 1000)\n",
    "yintl = fl(xint)\n",
    "yintq = fq(xint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "# Setting up fake data with artificial noise\n",
    "sample = 30\n",
    "x = np.linspace(1, 10 * np.pi, sample)\n",
    "y = np.cos(x) + np.log10(x) + np.random.randn(sample) / 10\n",
    "# Interpolating the data\n",
    "f = UnivariateSpline(x, y, s=1)\n",
    "# x.min and x.max are used to make sure we do not\n",
    "# go beyond the boundaries of the data for the\n",
    "# interpolation.\n",
    "xint = np.linspace(x.min(), x.max(), 1000)\n",
    "yint = f(xint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "# Defining a function\n",
    "ripple = lambda x, y: np.sqrt(x**2 + y**2)+np.sin(x**2 + y**2)\n",
    "# Generating gridded data. The complex number defines\n",
    "# how many steps the grid data should have. Without the\n",
    "# complex number mgrid would only create a grid data structure\n",
    "# with 5 steps.\n",
    "grid_x, grid_y = np.mgrid[0:5:1000j, 0:5:1000j]\n",
    "# Generating sample that interpolation function will see\n",
    "xy = np.random.rand(1000, 2)\n",
    "sample = ripple(xy[:,0] * 5 , xy[:,1] * 5)\n",
    "# Interpolating data with a cubic\n",
    "grid_z0 = griddata(xy * 5, sample, (grid_x, grid_y), method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\scipy\\interpolate\\fitpack2.py:931: UserWarning: ier=39779\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import SmoothBivariateSpline as SBS\n",
    "# Defining a function\n",
    "ripple = lambda x, y: np.sqrt(x**2 + y**2)+np.sin(x**2 + y**2)\n",
    "# Generating sample that interpolation function will see\n",
    "xy= np.random.rand(1000, 2)\n",
    "x, y = xy[:,0], xy[:,1]\n",
    "sample = ripple(xy[:,0] * 5 , xy[:,1] * 5)\n",
    "# Interpolating data\n",
    "fit = SBS(x * 5, y * 5, sample, s=0.01, kx=4, ky=4)\n",
    "interp = fit(np.linspace(0, 5, 1000), np.linspace(0, 5, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.3 Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.296467785724373, 1.3977971338839115e-09)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "# Defining function to integrate\n",
    "func = lambda x: np.cos(np.exp(x)) ** 2\n",
    "# Integrating function with upper and lower\n",
    "# limits of 0 and 3, respectively\n",
    "solution = quad(func, 0, 3)\n",
    "print solution\n",
    "# The first element is the desired value\n",
    "# and the second is the error.\n",
    "# (1.296467785724373, 1.397797186265988e-09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsolution = 5.10034506754\n",
      "dsolution = 5.23192054843\n",
      "The difference is 0.131575480886\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad, trapz\n",
    "# Setting up fake data\n",
    "x = np.sort(np.random.randn(150) * 4 + 4).clip(0,5)\n",
    "func = lambda x: np.sin(x) * np.cos(x ** 2) + 1\n",
    "y = func(x)\n",
    "# Integrating function with upper and lower\n",
    "# limits of 0 and 5, respectively\n",
    "fsolution = quad(func, 0, 5)\n",
    "dsolution = trapz(y, x=x)\n",
    "print('fsolution = ' + str(fsolution[0]))\n",
    "print('dsolution = ' + str(dsolution))\n",
    "print('The difference is ' + str(np.abs(fsolution[0] - dsolution)))\n",
    "# fsolution = 5.10034506754\n",
    "# dsolution = 5.04201628314\n",
    "# The difference is 0.0583287843989."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.4 Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Constructing a random array with 1000 elements\n",
    "x = np.random.randn(1000)\n",
    "# Calculating several of the built-in methods\n",
    "# that numpy.array has\n",
    "mean = x.mean()\n",
    "std = x.std()\n",
    "var = x.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "# Set up the sample range\n",
    "x = np.linspace(-5,5,1000)\n",
    "# Here set up the parameters for the normal distribution,\n",
    "# where loc is the mean and scale is the standard deviation.\n",
    "dist = norm(loc=0, scale=1)\n",
    "# Retrieving norm's PDF and CDF\n",
    "pdf = dist.pdf(x)\n",
    "cdf = dist.cdf(x)\n",
    "# Here we draw out 500 random values from the norm.\n",
    "sample = dist.rvs(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import geom\n",
    "# Here set up the parameters for the geometric distribution.\n",
    "p = 0.5\n",
    "dist = geom(p)\n",
    "# Set up the sample range.\n",
    "x = np.linspace(0, 5, 1000)\n",
    "# Retrieving geom's PMF and CDF\n",
    "pmf = dist.pmf(x)\n",
    "cdf = dist.cdf(x)\n",
    "# Here we draw out 500 random values.\n",
    "sample = dist.rvs(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normaltest output\n",
      "Z-score = 0.0320796718658\n",
      "P-value = 0.984088117206\n",
      "\n",
      "kstest output for the Normal distribution\n",
      " D = 0.0841666088488\n",
      "P-value = 0.458909133506\n",
      "\n",
      "kstest output for the Wald distribution\n",
      " D = 0.573001391524\n",
      "P-value = 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Generating a normal distribution sample\n",
    "# with 100 elements\n",
    "sample = np.random.randn(100)\n",
    "# normaltest tests the null hypothesis.\n",
    "out = stats.normaltest(sample)\n",
    "print('normaltest output')\n",
    "print('Z-score = ' + str(out[0]))\n",
    "print('P-value = ' + str(out[1]))\n",
    "# kstest is the Kolmogorov-Smirnov test for goodness of fit.\n",
    "# Here its sample is being tested against the normal distribution.\n",
    "# D is the KS statistic and the closer it is to 0 the better.\n",
    "out = stats.kstest(sample, 'norm')\n",
    "print('\\nkstest output for the Normal distribution')\n",
    "print(' D = ' + str(out[0]))\n",
    "print('P-value = ' + str(out[1]))\n",
    "# Similarly, this can be easily tested against other distributions,\n",
    "# like the Wald distribution.\n",
    "out = stats.kstest(sample, 'wald')\n",
    "print('\\nkstest output for the Wald distribution')\n",
    "print(' D = ' + str(out[0]))\n",
    "print('P-value = ' + str(out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmonic mean = 0.309528933952\n",
      "\n",
      "Trimmed mean = 0.107303124434\n",
      "\n",
      "Skewness = 0.0115818044833\n",
      "\n",
      "Size = 100\n",
      "Min = -2.4561246868\n",
      "Max = 2.83012001143\n",
      "Mean = 0.0938503871389\n",
      "Variance = 1.13395549716\n",
      "Skewness = 0.0115818044833\n",
      "Kurtosis = -0.0349635587309\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "# Generating a normal distribution sample\n",
    "# with 100 elements\n",
    "sample = np.random.randn(100)\n",
    "# The harmonic mean: Sample values have to\n",
    "# be greater than 0.\n",
    "out = stats.hmean(sample[sample > 0])\n",
    "print('Harmonic mean = ' + str(out))\n",
    "# The mean, where values below -1 and above 1 are\n",
    "# removed for the mean calculation\n",
    "out = stats.tmean(sample, limits=(-1, 1))\n",
    "print('\\nTrimmed mean = ' + str(out))\n",
    "# Calculating the skewness of the sample\n",
    "out = stats.skew(sample)\n",
    "print('\\nSkewness = ' + str(out))\n",
    "# Additionally, there is a handy summary function called\n",
    "# describe, which gives a quick look at the data.\n",
    "out = stats.describe(sample)\n",
    "print('\\nSize = ' + str(out[0]))\n",
    "print('Min = ' + str(out[1][0]))\n",
    "print('Max = ' + str(out[1][1]))\n",
    "print('Mean = ' + str(out[2]))\n",
    "print('Variance = ' + str(out[3]))\n",
    "print('Skewness = ' + str(out[4]))\n",
    "print('Kurtosis = ' + str(out[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.5 Spatial and Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster import vq\n",
    "# Creating data\n",
    "c1 = np.random.randn(100, 2) + 5\n",
    "c2 = np.random.randn(30, 2) - 5\n",
    "c3 = np.random.randn(50, 2)\n",
    "# Pooling all the data into one 180 x 2 array\n",
    "data = np.vstack([c1, c2, c3])\n",
    "# Calculating the cluster centroids and variance\n",
    "# from kmeans\n",
    "centroids, variance = vq.kmeans(data, 3)\n",
    "# The identified variable contains the information\n",
    "# we need to separate the points in clusters\n",
    "# based on the vq function.\n",
    "identified, distance = vq.vq(data, centroids)\n",
    "# Retrieving coordinates for points in each vq\n",
    "# identified core\n",
    "vqc1 = data[identified == 0]\n",
    "vqc2 = data[identified == 1]\n",
    "vqc3 = data[identified == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import scipy.cluster.hierarchy as hy\n",
    "\n",
    "# Creating a cluster of clusters function\n",
    "def clusters(number = 20, cnumber = 5, csize = 10):\n",
    "    # Note that the way the clusters are positioned is Gaussian randomness.\n",
    "    rnum = np.random.rand(cnumber, 2)\n",
    "    rn = rnum[:,0] * number\n",
    "    rn = rn.astype(int)\n",
    "    rn[np.where(rn < 5 )] = 5\n",
    "    rn[np.where(rn > number/2. )] = round(number / 2., 0)\n",
    "    ra = rnum[:,1] * 2.9\n",
    "    ra[np.where(ra < 1.5)] = 1.5\n",
    "    cls = np.random.randn(number, 3) * csize\n",
    "\n",
    "    # Random multipliers for central point of cluster\n",
    "    rxyz = np.random.randn(cnumber-1, 3)\n",
    "    for i in xrange(cnumber-1):\n",
    "        tmp = np.random.randn(rn[i+1], 3)\n",
    "        x = tmp[:,0] + ( rxyz[i,0] * csize )\n",
    "        y = tmp[:,1] + ( rxyz[i,1] * csize )\n",
    "        z = tmp[:,2] + ( rxyz[i,2] * csize )\n",
    "        tmp = np.column_stack([x,y,z])\n",
    "        cls = np.vstack([cls,tmp])\n",
    "        return cls\n",
    "\n",
    "# Generate a cluster of clusters and distance matrix.\n",
    "cls = clusters()\n",
    "D = pdist(cls[:,0:2])\n",
    "D = squareform(D)\n",
    "\n",
    "# Compute and plot first dendrogram.\n",
    "fig = mpl.figure(figsize=(8,8))\n",
    "ax1 = fig.add_axes([0.09,0.1,0.2,0.6])\n",
    "Y1 = hy.linkage(D, method='complete')\n",
    "cutoff = 0.3 * np.max(Y1[:, 2])\n",
    "Z1 = hy.dendrogram(Y1, orientation='right', color_threshold=cutoff)\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)\n",
    "\n",
    "# Compute and plot second dendrogram.\n",
    "ax2 = fig.add_axes([0.3,0.71,0.6,0.2])\n",
    "Y2 = hy.linkage(D, method='average')\n",
    "cutoff = 0.3 * np.max(Y2[:, 2])\n",
    "Z2 = hy.dendrogram(Y2, color_threshold=cutoff)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)\n",
    "\n",
    "# Plot distance matrix.\n",
    "ax3 = fig.add_axes([0.3,0.1,0.6,0.6])\n",
    "idx1 = Z1['leaves']\n",
    "idx2 = Z2['leaves']\n",
    "D = D[idx1,:]\n",
    "D = D[:,idx2]\n",
    "ax3.matshow(D, aspect='auto', origin='lower', cmap=mpl.cm.YlGnBu)\n",
    "ax3.xaxis.set_visible(False)\n",
    "ax3.yaxis.set_visible(False)\n",
    "# Plot colorbar.\n",
    "fig.savefig('cluster_hy_f01.pdf', bbox = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same imports and cluster function from the previous example\n",
    "# follow through here.\n",
    "# Here we define a function to collect the coordinates of\n",
    "# each point of the different clusters.\n",
    "def group(data, index):\n",
    "    number = np.unique(index)\n",
    "    groups = []\n",
    "    for i in number:\n",
    "        groups.append(data[index == i])\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Creating a cluster of clusters\n",
    "cls = clusters()\n",
    "# Calculating the linkage matrix\n",
    "Y = hy.linkage(cls[:,0:2], method='complete')\n",
    "# Here we use the fcluster function to pull out a\n",
    "# collection of flat clusters from the hierarchical\n",
    "# data structure. Note that we are using the same\n",
    "# cutoff value as in the previous example for the dendrogram\n",
    "# using the 'complete' method.\n",
    "cutoff = 0.3 * np.max(Y[:, 2])\n",
    "index = hy.fcluster(Y, cutoff, 'distance')\n",
    "# Using the group function, we group points into their\n",
    "# respective clusters.\n",
    "groups = group(cls, index)\n",
    "# Plotting clusters\n",
    "fig = mpl.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "colors = ['r', 'c', 'b', 'g', 'orange', 'k', 'y', 'gray']\n",
    "\n",
    "for i, g in enumerate(groups):\n",
    "    i = np.mod(i, len(colors))\n",
    "    ax.scatter(g[:,0], g[:,1], c=colors[i], edgecolor='none', s=50)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)\n",
    "    \n",
    "fig.savefig('cluster_hy_f02.pdf', bbox = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.6 Signal and Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-f58f90934215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'space/*.JPG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Opening up the first image for loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# Starting loop and continue co-adding new images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imsave\n",
    "from glob import glob\n",
    "# Getting the list of files in the directory\n",
    "files = glob('space/*.JPG')\n",
    "# Opening up the first image for loop\n",
    "im1 = imread(files[0]).astype(np.float32)\n",
    "# Starting loop and continue co-adding new images\n",
    "for i in xrange(1, len(files)):\n",
    "    print i\n",
    "    im1 += imread(files[i]).astype(np.float32)\n",
    "# Saving img\n",
    "imsave('stacked_image.jpg', im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-e70a9142f5ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'space/*.JPG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Opening up the first image for looping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mim2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imsave\n",
    "from glob import glob\n",
    "# This function allows us to place in the\n",
    "# brightest pixels per x and y position between\n",
    "# two images. It is similar to PIL's\n",
    "# ImageChop.Lighter function.\n",
    "def chop_lighter(image1, image2):\n",
    "    s1 = np.sum(image1, axis=2)\n",
    "    s2 = np.sum(image2, axis=2)\n",
    "    \n",
    "    index = s1 < s2\n",
    "    image1[index, 0] = image2[index, 0]\n",
    "    image1[index, 1] = image2[index, 1]\n",
    "    image1[index, 2] = image2[index, 2]\n",
    "    return image1\n",
    "\n",
    "# Getting the list of files in the directory\n",
    "files = glob('space/*.JPG')\n",
    "# Opening up the first image for looping\n",
    "im1 = imread(files[0]).astype(np.float32)\n",
    "im2 = np.copy(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.7 Sparse Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numpy array data size: 72000000 bytes\n",
      "The sparse matrix data size: 720000 bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import eigh\n",
    "import scipy.sparse\n",
    "import time\n",
    "N = 3000\n",
    "# Creating a random sparse matrix\n",
    "m = scipy.sparse.rand(N, N)\n",
    "# Creating an array clone of it\n",
    "a = m.toarray()\n",
    "print('The numpy array data size: ' + str(a.nbytes) + ' bytes')\n",
    "print('The sparse matrix data size: ' + str(m.data.nbytes) + ' bytes')\n",
    "# Non-sparse\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    3.8 Reading and Writing Files Beyond NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
