{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 SciKit: Taking SciPy One Step Further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#     4.1 Scikit-Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Dynamic Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "import scipy.ndimage as ndimage\n",
    "import skimage.filter as skif\n",
    "\n",
    "# Generating data points with a non-uniform background\n",
    "x = np.random.uniform(low=0, high=100, size=20).astype(int)\n",
    "y = np.random.uniform(low=0, high=100, size=20).astype(int)\n",
    "\n",
    "# Creating image with non-uniform background\n",
    "func = lambda x, y: x**2 + y**2\n",
    "grid_x, grid_y = np.mgrid[-1:1:100j, -2:2:100j]\n",
    "bkg = func(grid_x, grid_y)\n",
    "bkg = bkg / np.max(bkg)\n",
    "\n",
    "# Creating points\n",
    "clean = np.zeros((100,100))\n",
    "clean[(x,y)] += 5\n",
    "clean = ndimage.gaussian_filter(clean, 3)\n",
    "clean = clean / np.max(clean)\n",
    "\n",
    "#Combining both the non-uniform background\n",
    "# and points\n",
    "fimg = bkg + clean\n",
    "fimg = fimg / np.max(fimg)\n",
    "\n",
    "# Defining minimum neighboring size of objects\n",
    "block_size = 3\n",
    "\n",
    "# Adaptive threshold function which returns image\n",
    "# map of structures that are different relative to\n",
    "# background\n",
    "adaptive_cut = skif.threshold_adaptive(fimg, block_size, offset=0)\n",
    "\n",
    "# Global threshold\n",
    "global_thresh = skif.threshold_otsu(fimg)\n",
    "global_cut = fimg > global_thresh\n",
    "\n",
    "# Creating figure to highlight difference between\n",
    "# adaptive and global threshold methods\n",
    "fig = mpl.figure(figsize=(8, 4))\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.imshow(fimg)\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax2.imshow(global_cut)\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)\n",
    "ax3 = fig.add_subplot(133)\n",
    "ax3.imshow(adaptive_cut)\n",
    "ax3.xaxis.set_visible(False)\n",
    "ax3.yaxis.set_visible(False)\n",
    "\n",
    "fig.savefig('scikit_image_f01.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Local Maxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "import scipy.ndimage as ndimage\n",
    "import skimage.morphology as morph\n",
    "\n",
    "# Generating data points with a non-uniform background\n",
    "x = np.random.uniform(low=0, high=200, size=20).astype(int)\n",
    "y = np.random.uniform(low=0, high=400, size=20).astype(int)\n",
    "# Creating image with non-uniform background\n",
    "func = lambda x, y: np.cos(x)+ np.sin(y)\n",
    "grid_x, grid_y = np.mgrid[0:12:200j, 0:24:400j]\n",
    "bkg = func(grid_x, grid_y)\n",
    "bkg = bkg / np.max(bkg)\n",
    "# Creating points\n",
    "clean = np.zeros((200,400))\n",
    "clean[(x,y)] += 5\n",
    "clean = ndimage.gaussian_filter(clean, 3)\n",
    "clean = clean / np.max(clean)\n",
    "# Combining both the non-uniform background\n",
    "# and points\n",
    "fimg = bkg + clean\n",
    "fimg = fimg / np.max(fimg)\n",
    "# Calculating local maxima\n",
    "lm1 = morph.is_local_maximum(fimg)\n",
    "x1, y1 = np.where(lm1.T == True)\n",
    "# Creating figure to show local maximum detection\n",
    "# rate success\n",
    "fig = mpl.figure(figsize=(8, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(fimg)\n",
    "ax.scatter(x1, y1, s=100, facecolor='none', edgecolor='#009999')\n",
    "ax.set_xlim(0,400)\n",
    "ax.set_ylim(0,200)\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyfits\n",
    "import matplotlib.pyplot as mpl\n",
    "import skimage.morphology as morph\n",
    "import skimage.exposure as skie\n",
    "\n",
    "# Loading astronomy image from an infrared space telescope\n",
    "img = pyfits.getdata('stellar_cluster.fits')[500:1500, 500:1500]\n",
    "# Prep file scikit-image environment and plotting\n",
    "limg = np.arcsinh(img)\n",
    "limg = limg / limg.max()\n",
    "low = np.percentile(limg, 0.25)\n",
    "high = np.percentile(limg, 99.5)\n",
    "opt_img = skie.exposure.rescale_intensity(limg, in_range=(low, high))\n",
    "# Calculating local maxima and filtering out noise\n",
    "lm = morph.is_local_maximum(limg)\n",
    "x1, y1 = np.where(lm.T == True)\n",
    "v = limg[(y1, x1)]\n",
    "lim = 0.5\n",
    "x2, y2 = x1[v > lim], y1[v > lim]\n",
    "# Creating figure to show local maximum detection\n",
    "# rate success\n",
    "fig = mpl.figure(figsize=(8,4))\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(opt_img)\n",
    "ax1.set_xlim(0, img.shape[1])\n",
    "ax1.set_ylim(0, img.shape[0])\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(opt_img)\n",
    "ax2.scatter(x2, y2, s=80, facecolor='none', edgecolor='#FF7400')\n",
    "ax2.set_xlim(0, img.shape[1])\n",
    "ax2.set_ylim(0, img.shape[0])\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)\n",
    "fig.savefig('scikit_image_f03.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets.samples_generator import make_regression\n",
    "# Generating synthetic data for training and testing\n",
    "X, y = make_regression(n_samples=100, n_features=2, n_informative=1,\\\n",
    "random_state=0, noise=50)\n",
    "# X and y are values for 3D space. We first need to train\n",
    "# the machine, so we split X and y into X_train, X_test,\n",
    "# y_train, and y_test. The *_train data will be given to the\n",
    "# model to train it.\n",
    "X_train, X_test = X[:80], X[-20:]\n",
    "y_train, y_test = y[:80], y[-20:]\n",
    "# Creating instance of model\n",
    "regr = linear_model.LinearRegression()\n",
    "# Training the model\n",
    "regr.fit(X_train, y_train)\n",
    "# Printing the coefficients\n",
    "print(regr.coef_)\n",
    "# [-10.25691752 90.5463984 ]\n",
    "# Predicting y-value based on training\n",
    "X1 = np.array([1.2, 4])\n",
    "print(regr.predict(X1))\n",
    "# 350.860363861\n",
    "# With the *_test data we can see how the result matches\n",
    "# the data the model was trained with.\n",
    "# It should be a good match as the *_train and *_test\n",
    "# data come from the same sample. Output: 1 is perfect\n",
    "# prediction and anything lower is worse.\n",
    "print(regr.score(X_test, y_test))\n",
    "# 0.949827492261\n",
    "fig = mpl.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "# ax = Axes3D(fig)\n",
    "# Data\n",
    "ax.scatter(X_train[:,0], X_train[:,1], y_train, facecolor='#00CC00')\n",
    "ax.scatter(X_test[:,0], X_test[:,1], y_test, facecolor='#FF7800')\n",
    "# Function with coefficient variables\n",
    "coef = regr.coef_\n",
    "line = lambda x1, x2: coef[0] * x1 + coef[1] * x2\n",
    "grid_x1, grid_x2 = np.mgrid[-2:2:10j, -2:2:10j]\n",
    "ax.plot_surface(grid_x1, grid_x2, line(grid_x1, grid_x2),\n",
    "alpha=0.1, color='k')\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.zaxis.set_visible(False)\n",
    "fig.savefig('scikit_learn_regression.pdf', bbox='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "# Creating data\n",
    "c1 = np.random.randn(100, 2) + 5\n",
    "c2 = np.random.randn(50, 2)\n",
    "# Creating a uniformly distributed background\n",
    "u1 = np.random.uniform(low=-10, high=10, size=100)\n",
    "u2 = np.random.uniform(low=-10, high=10, size=100)\n",
    "c3 = np.column_stack([u1, u2])\n",
    "# Pooling all the data into one 150 x 2 array\n",
    "data = np.vstack([c1, c2, c3])\n",
    "# Calculating the cluster with DBSCAN function.\n",
    "# db.labels_ is an array with identifiers to the\n",
    "# different clusters in the data.\n",
    "db = DBSCAN().fit(data, eps=0.95, min_samples=10)\n",
    "labels = db.labels_\n",
    "# Retrieving coordinates for points in each\n",
    "# identified core. There are two clusters\n",
    "# denoted as 0 and 1 and the noise is denoted\n",
    "# as -1. Here we split the data based on which\n",
    "# component they belong to.\n",
    "dbc1 = data[labels == 0]\n",
    "dbc2 = data[labels == 1]\n",
    "noise = data[labels == -1]\n",
    "# Setting up plot details\n",
    "x1, x2 = -12, 12\n",
    "y1, y2 = -12, 12\n",
    "fig = mpl.figure()\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "ax1 = fig.add_subplot(121, aspect='equal')\n",
    "ax1.scatter(c1[:,0], c1[:,1], lw=0.5, color='#00CC00')\n",
    "ax1.scatter(c2[:,0], c2[:,1], lw=0.5, color='#028E9B')\n",
    "ax1.scatter(c3[:,0], c3[:,1], lw=0.5, color='#FF7800')\n",
    "ax1.xaxis.set_visible(False)\n",
    "ax1.yaxis.set_visible(False)\n",
    "ax1.set_xlim(x1, x2)\n",
    "ax1.set_ylim(y1, y2)\n",
    "ax1.text(-11, 10, 'Original')\n",
    "ax2 = fig.add_subplot(122, aspect='equal')\n",
    "ax2.scatter(dbc1[:,0], dbc1[:,1], lw=0.5, color='#00CC00')\n",
    "ax2.scatter(dbc2[:,0], dbc2[:,1], lw=0.5, color='#028E9B')\n",
    "ax2.scatter(noise[:,0], noise[:,1], lw=0.5, color='#FF7800')\n",
    "ax2.xaxis.set_visible(False)\n",
    "ax2.yaxis.set_visible(False)\n",
    "ax2.set_xlim(x1, x2)\n",
    "ax2.set_ylim(y1, y2)\n",
    "ax2.text(-11, 10, 'DBSCAN identified')\n",
    "fig.savefig('scikit_learn_clusters.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4 http://www.scikit-learn.org/stable/modules/linear_model.html  \n",
    "5 http://www.scikit-learn.org/stable/modules/clustering.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
